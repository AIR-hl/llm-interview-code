{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad76860a",
   "metadata": {},
   "source": [
    "# Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0613,  0.0791, -1.4436, -0.9547,  0.9770,  0.0605,  0.5642,  2.0765,\n",
      "         1.8535, -0.3742])\n",
      "tensor([-65.,   5., -88., -58.,  60.,   4.,  35., 127., 113., -23.])\n",
      "tensor([-1.0628,  0.0818, -1.4388, -0.9483,  0.9810,  0.0654,  0.5723,  2.0765,\n",
      "         1.8476, -0.3761])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# int8 对称量化\n",
    "def int8_quantize(tensor):\n",
    "    \"\"\"\n",
    "    量化公式: quantized = round(tensor / scale)\n",
    "    \"\"\"\n",
    "    scale = (tensor.abs().max() / 127).item()  # 使用.item()获取标量值\n",
    "    quantized_tensor = (tensor / scale).round().clamp(-128, 127)\n",
    "    return quantized_tensor, scale\n",
    "\n",
    "# int8 反量化\n",
    "def int8_dequantize(quantized_tensor, scale):\n",
    "    \"\"\"\n",
    "    对int8量化张量进行反量化\n",
    "    \"\"\"\n",
    "    dequantized_tensor = quantized_tensor * scale\n",
    "    return dequantized_tensor\n",
    "\n",
    "t=torch.randn(10)\n",
    "quantized_tensor, scale = int8_quantize(t)\n",
    "dequantized_tensor = int8_dequantize(quantized_tensor, scale)\n",
    "\n",
    "print(t)\n",
    "print(quantized_tensor)\n",
    "print(dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78f1ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0000,  2.5000, -0.5000,  4.2000,  0.8000, -1.2000,  3.1000,  0.0000,\n",
      "         2.0000, -0.8000])\n",
      "tensor([ -24.,   47.,  -95.,  127.,  -34., -128.,   75.,  -71.,   23., -109.])\n",
      "tensor([ 1.0024,  2.5059, -0.5012,  4.2000,  0.7906, -1.2000,  3.0988,  0.0071,\n",
      "         1.9976, -0.7976])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# int8 非对称量化\n",
    "def int8_asym_quantize(tensor):\n",
    "    \"\"\"\n",
    "    量化公式: quantized = round((tensor - zero_point) / scale)\n",
    "    \"\"\"\n",
    "    # 计算张量的最小值和最大值\n",
    "    tensor_min = tensor.min().item()\n",
    "    tensor_max = tensor.max().item()\n",
    "    \n",
    "    scale = (tensor_max - tensor_min) / 255.0\n",
    "    \n",
    "    # 计算zero_point，使得tensor_min对应到-128\n",
    "    # zero_point = tensor_min - scale * (-128)\n",
    "    zero_point = tensor_min + scale * 128\n",
    "    \n",
    "    # 进行量化: quantized = round((tensor - zero_point) / scale)\n",
    "    quantized_tensor = torch.round((tensor - zero_point) / scale)\n",
    "    quantized_tensor = quantized_tensor.clamp(-128, 127)\n",
    "    \n",
    "    return quantized_tensor, scale, zero_point\n",
    "\n",
    "# int8 非对称反量化\n",
    "def int8_asym_dequantize(quantized_tensor, scale, zero_point):\n",
    "    \"\"\"\n",
    "    对int8非对称量化张量进行反量化\n",
    "    \n",
    "    反量化公式: dequantized = quantized * scale + zero_point\n",
    "    \"\"\"\n",
    "    dequantized_tensor = quantized_tensor * scale + zero_point\n",
    "    return dequantized_tensor\n",
    "\n",
    "# 测试非对称量化\n",
    "\n",
    "t = torch.tensor([1.0, 2.5, -0.5, 4.2, 0.8, -1.2, 3.1, 0.0, 2.0, -0.8])\n",
    "quantized_tensor, scale, zero_point = int8_asym_quantize(t)\n",
    "dequantized_tensor = int8_asym_dequantize(quantized_tensor, scale, zero_point)\n",
    "\n",
    "print(t)\n",
    "print(quantized_tensor)\n",
    "print(dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6139c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
