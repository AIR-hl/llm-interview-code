{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16289e5a",
   "metadata": {},
   "source": [
    "# Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78414fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def create_attention_mask(input_ids, pad_token_id=0, causal=True):\n",
    "    batch_size, seq_len = input_ids.size()\n",
    "\n",
    "    padding_mask = (input_ids == pad_token_id).view(batch_size, 1, 1, seq_len)\n",
    "\n",
    "    if causal:\n",
    "        causal_mask = torch.triu(\n",
    "            torch.ones(seq_len, seq_len, dtype=torch.bool),\n",
    "            diagonal=1 # 对角线及以下为False，对角线以上为True\n",
    "        )\n",
    "        causal_mask = causal_mask.view(1, 1, *causal_mask.shape)\n",
    "        mask = padding_mask | causal_mask # [batch_size, 1, seq_len, seq_len] 是为了方便 torch.mask_filled广播\n",
    "    else:\n",
    "        mask = padding_mask.expand(batch_size, 1, seq_len, seq_len) # [batch_size, 1, seq_len, seq_len]\n",
    "    return mask\n",
    "\n",
    "# 使用时：\n",
    "# mask = get_attention_mask(input_ids, pad_token_id=0)\n",
    "# attention_scores = attention_weights.masked_fill(mask, float('-inf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
